{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dec1f-a5d6-4a3a-bf5d-5d01babda56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d51f5f-3b90-4715-9ee6-a2bbe86608fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CXR-Reason_image_filenames') as f:\n",
    "    image_filenames=[i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d224d1e-d3af-4c0e-90ea-343e5235ac51",
   "metadata": {},
   "source": [
    "# Golden Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9690f6b-e537-4286-a915-0b67fd0b6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./gold_dataset/gold_attributes_relations_500pts_500studies1st.txt', sep='\\t')\n",
    "attributes_gold_df=df[df.categoryID.apply(lambda x: True if x in ['anatomicalfinding','disease'] else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1932fda-2dc4-48cc-9714-b7abf128462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=[]\n",
    "for idx, data in tqdm(attributes_gold_df.iterrows(), total=len(attributes_gold_df)):\n",
    "    patient='p'+str(data['patient_id'])\n",
    "    study='s'+str(data['study_id'])\n",
    "    image=data['image_id'].replace('.dcm','.jpg')\n",
    "    image_path=f'{patient[:3]}/{patient}/{study}/{image}'\n",
    "    if 'files/'+image_path in image_filenames:\n",
    "        filtered_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89412d-c75a-4c0e-89f7-76de2cea6a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attributes_gold_df=pd.DataFrame(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43e226-14c6-4216-b7a8-364e5df8d97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patient_level_findings={}\n",
    "patient_level_disease={}\n",
    "for idx, row in attributes_gold_df.iterrows():\n",
    "    patient_id=row['patient_id']\n",
    "    if patient_id not in patient_level_findings:\n",
    "        patient_level_findings[patient_id]=[]\n",
    "        patient_level_disease[patient_id]=[]\n",
    "\n",
    "    if row['categoryID']=='disease':\n",
    "        patient_level_disease[patient_id].append(row['label_name']+\"+\"+row['context'])\n",
    "    else:\n",
    "        if row['context']=='yes':\n",
    "            patient_level_findings[patient_id].append([row['bbox'],row['label_name']])\n",
    "\n",
    "patient_level_disease={k:[vi.split('+') for vi in list(set(v))] for k,v in patient_level_disease.items() if len(v)>0}\n",
    "patient_level_findings={k:v for k,v in patient_level_findings.items() if len(v)>0}\n",
    "patient_level_findings={k:v for k,v in patient_level_findings.items() if k in patient_level_disease}\n",
    "\n",
    "questions=[]\n",
    "for k, v in patient_level_disease.items():\n",
    "    if k not in patient_level_findings:\n",
    "        continue\n",
    "    for vi in v:\n",
    "        disease=vi[0]\n",
    "        yesorno=vi[1]\n",
    "        question=f'Based on the given chest X-ray, does this patient have {disease}?'\n",
    "        questions.append({'patient_id':k,'question':question, 'type':'no_findings', 'type_specific':'no_findings', 'answer': yesorno})\n",
    "        temp_question=''\n",
    "\n",
    "        for finding in list(set([i[1] for i in patient_level_findings[k]])):\n",
    "            temp_question=temp_question+f'The patient has {finding}. '\n",
    "            questions.append({'patient_id':k,'question':f'The patient has {finding}. '+question, 'type':'finding', 'type_specific':finding, 'answer': yesorno})\n",
    "        questions.append({'patient_id':k,'question':temp_question+question, 'type':'all_findings', 'type_specific':'all_findings', 'answer': yesorno})\n",
    "        \n",
    "        for findings in patient_level_findings[k]:\n",
    "            anatomy=findings[0]\n",
    "            finding=findings[1]\n",
    "            questions.append({'patient_id':k,'question':f'The patient has {finding} at {anatomy}. '+question, 'type':'finding+anatomy', 'type_specific':finding+\"+\"+anatomy, 'answer': yesorno})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9624587-502f-4f37-a2c4-3622ea9c4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dict(di, image_path, idx):\n",
    "    return {'image': image_path, 'question_type':di['type'], 'question_type_specific':di['type_specific'], 'sys': \"\",\n",
    "            'question_id': idx, 'question': di['question'].strip(),'answer': di['answer'].strip(), 'conversations': [\n",
    "                {'from': 'human', 'value': '<image>\\n'+di['question']},\n",
    "                {'from': 'gpt', 'value': di['answer'].strip()}\n",
    "            ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04992947-cf95-444f-86a9-3e965163489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids=attributes_gold_df[['patient_id',\t'study_id',\t'image_id']].drop_duplicates()\n",
    "patient_ids.set_index('patient_id',inplace=True)\n",
    "final_questions=[]\n",
    "for idx, q in enumerate(questions):\n",
    "    patient='p'+str(q['patient_id'])\n",
    "    study='s'+str(patient_ids.loc[q['patient_id']]['study_id'])\n",
    "    image=patient_ids.loc[q['patient_id']]['image_id'].replace('.dcm','.jpg')\n",
    "    image_path=f'{patient[:3]}/{patient}/{study}/{image}'\n",
    "\n",
    "    final_questions.append(process_dict(q, image_path, idx))\n",
    "\n",
    "final_questions=pd.DataFrame(final_questions)\n",
    "final_questions=final_questions.groupby(['image','question','question_type']).first()\n",
    "final_questions.reset_index(inplace=True)\n",
    "final_questions=final_questions.set_index('question_id').reset_index(drop=True).reset_index().rename(columns={'index':'question_id'}).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f15991-f170-4df5-b733-41c8e631b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CXR-Reason-Golden.jsonl', 'w') as f:\n",
    "    f.write(json.dumps(final_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c3200-f1d7-48cc-b07f-988a58806537",
   "metadata": {},
   "source": [
    "# Silver Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2512c-5b93-49d2-a9e4-d8f3d07b8e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates=[]\n",
    "for fp in tqdm(glob('./silver_dataset/scene_graph/*.json')):\n",
    "    with open(fp) as f:\n",
    "        text=f.read()\n",
    "    if 'disease|' in text:\n",
    "        data=json.loads(text)    \n",
    "        patient='p'+str(data['patient_id'])\n",
    "        study='s'+str(data['study_id'])\n",
    "        image=data['image_id']\n",
    "        image_path=f'{patient[:3]}/{patient}/{study}/{image}.jpg'\n",
    "        if 'files/'+image_path in image_filenames:\n",
    "            candidates.append(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ca8b4-ac94-4ec1-ad58-777ae2af186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda0c8c-a927-40bc-8b2b-a819c38e7bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dict(di, image_path, idx):\n",
    "    return {'image': image_path, 'question_type':di['type'], 'question_type_specific':di['type_specific'], 'sys': \"\",\n",
    "            'question_id': idx, 'question': di['question'].strip(),'answer': di['answer'].strip(), 'conversations': [\n",
    "                {'from': 'human', 'value': '<image>\\n'+di['question']},\n",
    "                {'from': 'gpt', 'value': di['answer'].strip()}\n",
    "            ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ab08b-10de-4a1f-b799-5169f4f34ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[]\n",
    "idx=0\n",
    "for fp in tqdm(candidates):\n",
    "    with open(fp) as f:\n",
    "        data=json.loads(f.read())\n",
    "    patient='p'+str(data['patient_id'])\n",
    "    study='s'+str(data['study_id'])\n",
    "    image=data['image_id']\n",
    "    image_path=f'{patient[:3]}/{patient}/{study}/{image}.jpg'\n",
    "    \n",
    "    diseases=[]\n",
    "    findings=[]\n",
    "    for a in data['attributes']:\n",
    "        anatomy=a['bbox_name']\n",
    "        for i in a['attributes']:\n",
    "            for j in i:\n",
    "                if j.startswith('disease'):\n",
    "                    diseases.append(j.split('|')[-1].strip()+'+'+j.split('|')[1].strip())\n",
    "                if j.startswith('anatomicalfinding'):\n",
    "                    if '|yes|' in j:\n",
    "                        findings.append(anatomy+'+'+j.split('|yes|')[-1].strip())\n",
    "\n",
    "    diseases=[vi.split('+') for vi in list(set(diseases))]\n",
    "    findings=[vi.split('+') for vi in list(set(findings))]\n",
    "\n",
    "    if len(findings)>0:\n",
    "        for vi in diseases:\n",
    "            disease=vi[0]\n",
    "            yesorno=vi[1]\n",
    "            question=f'Based on the given chest X-ray, does this patient have {disease}?'\n",
    "            \n",
    "            questions.append(process_dict({'question':question, 'type':'no_findings', 'type_specific':'no_findings', 'answer': yesorno},image_path,idx))\n",
    "            idx+=1\n",
    "            \n",
    "            temp_question=''\n",
    "            for finding in list(set([i[1] for i in findings])):\n",
    "                temp_question=temp_question+f'The patient has {finding}. '\n",
    "                questions.append(process_dict({'question':f'The patient has {finding}. '+question, 'type':'finding', 'type_specific':finding, 'answer': yesorno},image_path,idx))\n",
    "                idx+=1\n",
    "            questions.append(process_dict({'question':temp_question+question, 'type':'all_findings', 'type_specific':'all_findings', 'answer': yesorno},image_path,idx))\n",
    "            idx+=1\n",
    "            \n",
    "            for _finding in findings:\n",
    "                anatomy=_finding[0]\n",
    "                finding=_finding[1]\n",
    "                questions.append(process_dict({'question':f'The patient has {finding} at {anatomy}. '+question, 'type':'finding+anatomy', 'type_specific':finding+\"+\"+anatomy, 'answer': yesorno},image_path,idx))\n",
    "                idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa63b0-8d4e-4d21-ae63-9c92505d0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bace26a-e93f-4694-9a3e-3116a9f54dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=pd.DataFrame(questions)\n",
    "questions=questions.groupby(['image','question','question_type']).first()\n",
    "questions.reset_index(inplace=True)\n",
    "questions['disease']=questions.conversations.apply(lambda x: x[0]['value'].split('this patient have')[-1].rstrip('?').strip())\n",
    "no_findings=questions[questions.question_type=='no_findings']\n",
    "all_findings=questions[questions.question_type=='all_findings']\n",
    "\n",
    "no_findings_sampled=no_findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "all_findings_sampled=all_findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "findings=pd.DataFrame([a for _, a in questions.iterrows() if a['question_type']=='finding'])\n",
    "findings_sampled=findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "anatomical_questions=pd.DataFrame([a for _, a in questions.iterrows() if a['question_type']=='finding+anatomy'])\n",
    "anatomical_questions_sampled=anatomical_questions.groupby(['image','disease']).sample(1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd513e0-20ab-417e-8bc6-c3c7bc0815c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df=pd.concat([no_findings_sampled,all_findings_sampled,findings_sampled,anatomical_questions_sampled])\n",
    "remove_index_list=[j for i in sampled_df.groupby(['image','disease'])['question_id'].agg(list)[sampled_df.groupby(['image','disease']).count()['question']<4].values for j in i]\n",
    "sampled_df.set_index('question_id',inplace=True)\n",
    "sampled_df.drop(index=remove_index_list,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9f99c-d37b-4819-9c9a-d17c650b9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('IMAGE_EXCEPTION.txt') as f:\n",
    "    image_exception=[i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3ec94-1b52-4efc-a9c4-ea323be30ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_index_list=[]\n",
    "for idx, row in tqdm(sampled_df.iterrows(), total=len(sampled_df)):\n",
    "    if row['image'] in image_exception:\n",
    "        remove_index_list.append(idx)\n",
    "sampled_df.drop(index=remove_index_list,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f996fe70-3e89-43aa-90e0-cfdfea11e114",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_questions=sampled_df.reset_index(drop=True).reset_index().rename(columns={'index':'question_id'}).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503514ac-a89b-4864-8315-fdcfea46e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CXR-Reason-Silver.jsonl', 'w') as f:\n",
    "    f.write(json.dumps(final_questions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-llama_factory_new]",
   "language": "python",
   "name": "conda-env-.conda-llama_factory_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
