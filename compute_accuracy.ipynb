{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46a6d7-584e-4ea2-acfe-42c027cd276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bef382-8c44-4e39-81de-68507a143469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(fp, answers, index_list=None):\n",
    "    with open(fp) as f:\n",
    "        data=[json.loads(l) for l in f.readlines()]\n",
    "    correct=[]\n",
    "    res=[]\n",
    "    model_name=None\n",
    "    if len(data)>0:\n",
    "        for d in data:\n",
    "            if index_list is not None:\n",
    "                if d['question_id'] not in index_list:\n",
    "                    continue\n",
    "            a=answers.loc[d['question_id']]\n",
    "            try:\n",
    "                pred=d['pred_response'].lower().strip()\n",
    "            except:\n",
    "                pred=d['pred_response'][0].lower().strip()\n",
    "            gt=d['gt_response'].lower().strip()\n",
    "            if pred==gt:\n",
    "                d['correct']=True\n",
    "            elif gt in pred:\n",
    "                if gt=='no' and 'not possible' in pred:\n",
    "                    d['correct']=True           \n",
    "                elif 'no' in pred.split() or 'no,' in pred.split() or 'no.' in pred.split():\n",
    "                    if gt=='yes':\n",
    "                        d['correct']=False\n",
    "                    else:\n",
    "                        d['correct']=True\n",
    "                elif 'yes' in pred.split() or 'yes,' in pred.split() or 'yes.' in pred.split():\n",
    "                    if gt=='yes':\n",
    "                        d['correct']=True\n",
    "                    else:\n",
    "                        d['correct']=False\n",
    "                else:\n",
    "                    d['correct']=False     \n",
    "            elif 'consistent with' in pred or 'may have' in pred or 'indicative of' in pred or 'evidence of' in pred:\n",
    "                if gt=='yes':\n",
    "                    disease=d['prompt'].split('this patient have')[-1].rstrip('?').strip()\n",
    "                    if '/' in disease:\n",
    "                        for di in disease.split('/'):\n",
    "                            if f'consistent with {di}' in pred or f'may have {di}' in pred or f'indicative of {di}' in pred or f'evidence of {di}' in pred:\n",
    "                                if 'not' in pred.split():\n",
    "                                    d['correct']=False\n",
    "                                else:\n",
    "                                    d['correct']=True\n",
    "                                break\n",
    "                    else:\n",
    "                        if f'consistent with {disease}' in pred or f'may have {disease}' in pred or f'indicative of {disease}' in pred or f'evidence of {disease}' in pred:\n",
    "                            if 'not' in pred.split():\n",
    "                                d['correct']=False\n",
    "                            else:\n",
    "                                d['correct']=True\n",
    "                else:\n",
    "                    disease=d['prompt'].split('this patient have')[-1].rstrip('?').strip()\n",
    "                    if '/' in disease:\n",
    "                        for di in disease.split('/'):\n",
    "                            if f'consistent with {di}' in pred or f'may have {di}' in pred or f'indicative of {di}' in pred or f'evidence of {di}' in pred:\n",
    "                                if 'not' in pred.split():\n",
    "                                    d['correct']=True\n",
    "                                else:\n",
    "                                    d['correct']=False\n",
    "                                break\n",
    "                    else:\n",
    "                        if f'consistent with {disease}' in pred or f'may have {disease}' in pred or f'indicative of {disease}' in pred or f'evidence of {disease}' in pred:\n",
    "                            if 'not' in pred.split():\n",
    "                                d['correct']=True\n",
    "                            else:\n",
    "                                d['correct']=False\n",
    "                if 'correct' not in d:\n",
    "                    d['correct']=False\n",
    "            else:\n",
    "                d['correct']=False\n",
    "            if 'LLaVA-NeXT'==d['model_id']:\n",
    "                if '7b' in fp:\n",
    "                    model_name='llava-onevision-qwen2-7b'\n",
    "                else:\n",
    "                    model_name='llava-onevision-qwen2-72b'\n",
    "            else:\n",
    "                model_name=d['model_id']\n",
    "            correct.append(d['correct'])\n",
    "            res.append(pred)\n",
    "    return model_name, correct, res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5e1a4-1c06-4d30-817a-c22e2bd2548b",
   "metadata": {},
   "source": [
    "# Balanced sampled evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86fa73-5d70-499e-8685-a0bca8e82b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=989\n",
    "with open('CXR-Reason-Golden.jsonl') as f:\n",
    "    answers=[json.loads(l) for l in f.readlines()][0]\n",
    "answers=pd.DataFrame(answers)\n",
    "answers['disease']=answers.conversations.apply(lambda x: x[0]['value'].split('this patient have')[-1].rstrip('?').strip())\n",
    "no_findings=answers[answers.question_type=='no_findings']\n",
    "all_findings=answers[answers.question_type=='all_findings']\n",
    "\n",
    "no_findings_sampled=no_findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "all_findings_sampled=all_findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "findings=pd.DataFrame([a for _, a in answers.iterrows() if a['question_type']=='findings'])\n",
    "findings_anatomical=pd.DataFrame([a for _, a in answers.iterrows() if a['question_type']=='findings+anatomy'])\n",
    "findings_sampled=findings.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "findings_anatomical_sampled=findings_anatomical.groupby(['image','disease']).sample(1, random_state=random_state)\n",
    "\n",
    "sampled_df=pd.concat([no_findings_sampled,all_findings_sampled,findings_sampled,findings_anatomical_sampled])\n",
    "\n",
    "index_list=sampled_df.question_id.tolist()\n",
    "answers.set_index('question_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0a27a-3342-42ba-a183-cb2f4628b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "result={}\n",
    "response={}\n",
    "for i in glob('GOLDEN_RESULT/*.jsonl'):\n",
    "    model_name, correct, res = calculate(fp, answers, index_list)\n",
    "    if model_name is not None:\n",
    "        result[model_name]=correct\n",
    "        response[model_name]=res\n",
    "\n",
    "for k, v in result.items():\n",
    "    answers[f'{k}_correct']=v\n",
    "for k, v in response.items():\n",
    "    answers[f'{k}_response']=v\n",
    "\n",
    "for k in result.keys():\n",
    "    print(k, len(answers[answers[f'{k}_correct']==True])/len(answers))\n",
    "print()\n",
    "question_types=answers.question_type.value_counts().index.tolist()\n",
    "\n",
    "for k in result.keys():\n",
    "    for qt in question_types:\n",
    "        temp_df=answers[answers.question_type==qt]    \n",
    "        print(k, qt, len(temp_df[temp_df[f'{k}_correct']==True])/len(temp_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190636c1-7940-4b11-a01d-1a46c009ba0b",
   "metadata": {},
   "source": [
    "#### CheXagent Disease Stratified Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ef1ca-0af3-45a8-9ed6-ce21c2ad8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers[answers.CheXagent_correct==True].groupby('disease').CheXagent_correct.value_counts()/answers.value_counts('disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af294d20-c0a1-4fb4-ab9e-f67b173dc1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_disease_df=pd.DataFrame()\n",
    "for qt in question_types:\n",
    "    temp_df=answers[answers.question_type==qt]  \n",
    "    qt_disease_df[qt]=temp_df[temp_df.CheXagent_correct==True].groupby('disease').CheXagent_correct.value_counts()/temp_df.value_counts('disease')\n",
    "qt_disease_df[['no_findings', 'findings', 'findings+anatomy', 'all_findings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d8cb3-6dc8-4da9-85ab-9afe57c16324",
   "metadata": {},
   "source": [
    "# Full Golden Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fa71d-9233-411b-ad78-7935641cba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CXR-Reason-Golden.jsonl') as f:\n",
    "    full_answers=[json.loads(l) for l in f.readlines()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a6e2eb-7d4b-4556-9973-ed1fc5dcc46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_answers=pd.DataFrame(full_answers)\n",
    "full_answers['disease']=full_answers.conversations.apply(lambda x: x[0]['value'].split('this patient have')[-1].rstrip('?').strip())\n",
    "full_answers.set_index('question_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f284ea-ddbc-4973-800c-b945f4053971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result={}\n",
    "response={}\n",
    "for i in glob('GOLDEN_RESULT/*.jsonl'):\n",
    "    model_name, correct, res = calculate(fp, full_answers)\n",
    "    if model_name is not None:\n",
    "        result[model_name]=correct\n",
    "        response[model_name]=res\n",
    "\n",
    "for k, v in result.items():\n",
    "    full_answers[f'{k}_correct']=v\n",
    "for k, v in response.items():\n",
    "    full_answers[f'{k}_response']=v\n",
    "\n",
    "for k in result.keys():\n",
    "    print(k, len(full_answers[full_answers[f'{k}_correct']==True])/len(full_answers))\n",
    "print()\n",
    "question_types=full_answers.question_type.value_counts().index.tolist()\n",
    "\n",
    "for k in result.keys():\n",
    "    for qt in question_types:\n",
    "        temp_df=full_answers[full_answers.question_type==qt]    \n",
    "        print(k, qt, len(temp_df[temp_df[f'{k}_correct']==True])/len(temp_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6b99b-57ae-4110-b745-f33b78e66be6",
   "metadata": {},
   "source": [
    "#### CheXagent Disease Stratified Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c245c-0c9b-449f-96e4-d44dd2453ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_answers[full_answers.CheXagent_correct==True].groupby('disease').CheXagent_correct.value_counts()/full_answers.value_counts('disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d41b9a-e31d-460f-8bab-c7df2fad1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt_disease_full_df=pd.DataFrame()\n",
    "for qt in question_types:\n",
    "    temp_df=full_answers[full_answers.question_type==qt]  \n",
    "    qt_disease_full_df[qt]=temp_df[temp_df.CheXagent_correct==True].groupby('disease').CheXagent_correct.value_counts()/temp_df.value_counts('disease')\n",
    "qt_disease_full_df[['no_findings', 'findings', 'findings+anatomy', 'all_findings']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b20fa-bb9b-41a6-99e8-6fd7e09f5acf",
   "metadata": {},
   "source": [
    "#### Specific Findings and Anatomical Structure Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb38d80-7260-4c6d-81c9-b979e990a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_answers[full_answers.CheXagent_correct==True].groupby('question_type_specific').CheXagent_correct.value_counts()/full_answers.value_counts('question_type_specific')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584893e8-0c87-4a04-b1c9-df8160a90461",
   "metadata": {},
   "source": [
    "#### Pneumonia result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0981f-0b04-4af5-b093-8e7a84d154d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia=full_answers[full_answers['disease'].str.contains('pneumonia')]\n",
    "pneumonia[pneumonia['CheXagent_correct']==True].groupby('question_type_specific').CheXagent_correct.value_counts().sort_values(ascending=False)/pneumonia.value_counts('question_type_specific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2bc2d-5f9c-4427-8908-736b9cbdca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_result=pneumonia[pneumonia['CheXagent_correct']==True].groupby('question_type_specific').CheXagent_correct.value_counts().sort_values(ascending=False)/pneumonia.value_counts('question_type_specific')\n",
    "pneumonia_result.loc[pneumonia.value_counts('question_type_specific').head(10).index.tolist()].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6473e49-bf7c-4f15-8909-e523756a0490",
   "metadata": {},
   "source": [
    "# Silver_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802370ba-ba53-4c65-a8dd-c89713639366",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CXR-Reason-Silver.jsonl') as f:\n",
    "    silver_answers=[json.loads(l) for l in f.readlines()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef1145-325a-480a-8b09-353121b66c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_answers=pd.DataFrame(silver_answers)\n",
    "silver_answers['disease']=silver_answers.conversations.apply(lambda x: x[0]['value'].split('this patient have')[-1].rstrip('?').strip())\n",
    "silver_answers.set_index('question_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065efe86-3272-488e-9807-1749066e054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result={}\n",
    "response={}\n",
    "for i in glob('SILVER_RESULT/*.jsonl'):\n",
    "    model_name, correct, res = calculate(fp, silver_answers)\n",
    "    if model_name is not None:\n",
    "        result[model_name]=correct\n",
    "        response[model_name]=res\n",
    "\n",
    "for k, v in result.items():\n",
    "    silver_answers[f'{k}_correct']=v\n",
    "for k, v in response.items():\n",
    "    silver_answers[f'{k}_response']=v\n",
    "\n",
    "for k in result.keys():\n",
    "    print(k, len(silver_answers[silver_answers[f'{k}_correct']==True])/len(silver_answers))\n",
    "print()\n",
    "question_types=silver_answers.question_type.value_counts().index.tolist()\n",
    "\n",
    "for k in result.keys():\n",
    "    for qt in question_types:\n",
    "        temp_df=silver_answers[silver_answers.question_type==qt]    \n",
    "        print(k, qt, len(temp_df[temp_df[f'{k}_correct']==True])/len(temp_df))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jupyter] *",
   "language": "python",
   "name": "conda-env-.conda-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
